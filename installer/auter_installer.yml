---
- hosts: all
  become: True
  gather_facts: False
  vars: 
    csv_file: ./auter_config.csv
    username: "none"
    appstatssource: "auter-manager"
    appstatsappid: "auter-manager"
    appstatsfunctionid: "installer"
  tasks:
    - name: Pre-check if server has configuration set in CSV file
      become: False
      changed_when: False
      local_action: command grep ^{{ inventory_hostname.split(':')[0] }}, {{ csv_file }}

    - name: Check if epel repo is present
      shell: time yum repolist | grep epel | wc -l
      register: epelPresent

    - name: add the rs-epel repo
      failed_when: False
      register: result
      yum:
        name: rs-epel-release
        state: latest
      when: epelPresent.stdout|int == 0
      
    - name: add the epel repo
      when: ( '"No Package" in result.msg' ) and epelPresent.stdout == 0

      yum:
        name: epel-release
        state: latest
      
    - name: install auter
      yum:
        name: auter
        state: latest

    - name: adjust the auter.conf file
      template:
        backup: yes
        src: auter.conf.j2
        dest: /etc/auter/auter.conf

    - name: add warning to not edit yum.conf exclude manually
      lineinfile:
        backup: yes
        line: "# WARNING: the excludes line is edited by auter_installer everytime it is run"
        insertbefore: "^exclude="
        dest: /etc/yum.conf

    - name: adjust the yum.conf excludes
      lineinfile:
        backup: yes
        dest: /etc/yum.conf
        state: present
        regexp: ^exclude
        line: exclude={{ lookup('csvfile', inventory_hostname.split(':')[0] + ' file=' + csv_file + ' col=1 delimiter=,') }}

    - name: Install configsnap
      yum:
        name: configsnap
        state: latest

    - name: create configsnap pre apply script
      lineinfile: 
        create: yes
        state: present
        dest: /etc/auter/pre-apply.d/01-configsnap-pre
        mode: 0755
        regexp: configsnap.*pre
        line: /usr/sbin/configsnap --silent -d /root -t auter-configsnap-$(date +%Y-%m-%d) -p pre
 
    - name: create configsnap post apply script
      lineinfile: 
        create: yes
        state: present
        dest: /etc/auter/post-apply.d/50-configsnap-post-apply
        mode: 0755
        regexp: configsnap.*post-update
        line: /usr/sbin/configsnap -d /root -t auter-configsnap-$(date +%Y-%m-%d) -p post-update &> /root/auter-configsnap-$(date +%Y-%m-%d)/configsnap/post-update.compare

    - name: create configsnap post reboot script
      lineinfile: 
        create: yes
        state: present
        dest: /etc/auter/post-reboot.d/99-configsnap-post-reboot
        mode: 0755
        regexp: configsnap.*post-reboot
        line: /usr/sbin/configsnap -d /root -t auter-configsnap-$(date +%Y-%m-%d) -p post-reboot &> /root/auter-configsnap-$(date +%Y-%m-%d)/configsnap/post-reboot.compare

    - name: check auter status
      shell: "auter --status"
      register: auterStatus

    - name: enable auter
      command: auter --enable
      when: "'auter is currently enabled' not in auterStatus.stdout"

# This section can be used if you have nimbus installed and configured
    - name: Check if nimbus path is /opt/nimbus
      stat: path=/opt/nimbus/probes/system/logmon/logmon.cfg
      register: nimbus_details

    - name: set path variable to use /opt/nimbus
      set_fact:
        nimbus_path: "{{ nimbus_details.stat.path }}"
      when: nimbus_details.stat.exists == True

    - name: check if nimbus path is /opt/nimsoft
      stat: path=/opt/nimsoft/probes/system/logmon/logmon.cfg
      register: nimbus_details
      when: nimbus_path is not defined

    - name: set path variable to is /opt/nimsoft
      set_fact:
        nimbus_path: "{{ nimbus_details.stat.path }}"
      when: nimbus_details.stat.exists == True

    - name: Create nimbus monitors in "{{ nimbus_path }}"
      blockinfile:
        backup: yes
        insertbefore: "</profiles>"
        marker: "# {mark} ANSIBLE MANAGED AUTER BLOCK"
        dest: /opt/nimsoft/probes/system/logmon/logmon.cfg
        block: |2
             <auter_monitors>
                active = yes
                interval = 7 min
                scanfile = /var/log/messages
                scanmode = updates
                alarm = yes
                qos = yes
                message = no
                subject =
                <watchers>
                   <errors>
                      active = yes
                      match = /.*auter.*ERROR:.*/
                      level = critical
                      subsystemid =
                      message =
                      restrict =
                      expect = no
                      abort = no
                      sendclear = no
                      count = no
                      separator =
                      suppid = $WATCHER
                      source =
                      target =
                      qos =
                      runcommandonmatch = no
                      commandexecutable =
                      commandarguments =
                   </errors>
                   <warnings>
                      active = yes
                      match = /.*auter.*WARNING:.*/
                      level = critical
                      subsystemid =
                      message =
                      restrict =
                      expect = no
                      abort = no
                      sendclear = no
                      count = no
                      separator =
                      suppid = $WATCHER
                      source =
                      target =
                      qos =
                      runcommandonmatch = no
                      commandexecutable =
                      commandarguments =
                   </warnings>
                </watchers>
             </auter_monitors>
      when: nimbus_path is defined

    - name: get number of nimbus processes
      shell: "ps aux | grep -c nimbus"
      register: nimbusProcessCountPre
      when: nimbus_path is defined

    - name: restart nimbus
      failed_when: False
      service:
        enabled: yes
        name: nimbus
        state: restart
        pattern: nimbus(controller)
      when: nimbus_path is defined

    # We are assuming the ~/.config/hammertime/config.yaml exists because you
    # will be using hammertime to execute these commands
    - name: Get SSO from ~/.config/hammertime/config.yaml
      become: false
      local_action:
        module: shell awk '/^\s+username:.*[a-z]/ {print $2;exit;}' $HOME/.config/hammertime/config.yaml
      register: username

    - name: Appstats report
      local_action:
        module: uri
        url: 'https://appstats.rackspace.com/appstats/event/'
        method: 'POST'
        HEADER_Content-Type: application/json
        body: '{
          "username": "{{ username.stdout }}",
          "status": "SUCCESS",
          "source": "{{ appstatssource }}",
          "appid": "{{ appstatsappid }}",
          "OS": "Linux",
          "functionid": "{{ appstatsfunctionid }}"
        }'
        body_format: json
      become: False
...
